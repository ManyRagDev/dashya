import os
import json
import time
from datetime import date, timedelta
from supabase import create_client, Client
from groq import Groq
from dotenv import load_dotenv  # <--- NOVA IMPORTA√á√ÉO

# --- CONFIGURA√á√ÉO ---
load_dotenv()  # <--- CARREGA O ARQUIVO .ENV

SUPABASE_URL = os.environ.get("VITE_SUPABASE_URL")
SUPABASE_KEY = os.environ.get("VITE_SUPABASE_ANON_KEY")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

# Inicializa√ß√£o dos Clientes
try:
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("SUPABASE_URL ou SUPABASE_KEY n√£o encontrados no .env")
        
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    groq_client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    print(f"‚ùå Erro de Configura√ß√£o: {e}")
    exit(1)

def get_knowledge_base():
    """L√™ o arquivo Markdown que cont√©m a intelig√™ncia do sistema."""
    brain_path = "backend/brain/knowledge_base.md"
    try:
        with open(brain_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Alerta: Arquivo '{brain_path}' n√£o encontrado. Usando base fallback.")
        return "Regra b√°sica: Se ROAS > 2.5, campanha est√° boa."

def fetch_metrics():
    """Busca as m√©tricas mais recentes no banco de dados."""
    try:
        response = supabase.table('daily_account_metrics') \
            .select("*") \
            .order('date', desc=True) \
            .limit(1) \
            .execute()
        
        if response.data:
            return response.data[0]
        return None
    except Exception as e:
        print(f"‚ùå Erro ao buscar m√©tricas: {e}")
        return None

def generate_insight():
    print("üß† Iniciando Dashya AI Analyst (Modo Expert)...")
    
    # 1. Coleta de Dados
    metrics = fetch_metrics()
    if not metrics:
        print("‚ùå Abortando: Sem dados de m√©tricas para analisar hoje.")
        return

    print(f"üìä Dados encontrados para data: {metrics.get('date')}")

    # 2. Carregamento do C√©rebro
    knowledge = get_knowledge_base()
    
    # 3. Engenharia de Prompt (Context Injection)
    system_prompt = f"""
    ATUE COMO: Um Estrategista S√™nior de Tr√°fego Pago (Media Buyer) especialista em Meta Ads.
    
    SUA INTELEIG√äNCIA VEM DESTE MANUAL T√âCNICO (N√ÉO INVENTE REGRAS):
    === IN√çCIO DO MANUAL ===
    {knowledge}
    === FIM DO MANUAL ===
    
    SUA MISS√ÉO:
    Analise as m√©tricas di√°rias fornecidas abaixo.
    Cruze os n√∫meros com as regras do manual (Ex: Regra 1 de Learning, Regra 21 de Fadiga, Benchmarks 2025).
    Gere um diagn√≥stico curto e uma a√ß√£o recomendada.
    
    DIRETRIZES DE RESPOSTA:
    1. **Cite a Regra:** Se identificar um padr√£o, diga explicitamente (ex: "Detectado LP Mismatch conforme Regra 8").
    2. **Benchmark:** Compare o CTR/CPC do usu√°rio com os benchmarks do manual.
    3. **A√ß√£o:** D√™ uma ordem clara (Pausar, Escalar, Refazer Criativo).
    4. **Tom de Voz:** Profissional, direto, anal√≠tico. Sem "eu acho".

    FORMATO DE SA√çDA OBRIGAT√ìRIO (JSON):
    {{
        "insight": "Frase de impacto para o card (max 10 palavras). Ex: 'Fadiga Criativa Detectada: Pause Agora'",
        "detailed_reason": "Explica√ß√£o t√©cnica de 2 frases citando a regra e os dados.",
        "sentiment": "positive" | "warning" | "critical",
        "confidence_score": 0-100 (Inteiro)
    }}
    """

    user_message = f"""
    DADOS DO CLIENTE (DATA: {metrics.get('date')}):
    - Gasto: R$ {metrics.get('spend', 0)}
    - Receita: R$ {metrics.get('revenue', 0)} (Se 0, calcule ROAS baseado no Spend)
    - ROAS: {metrics.get('roas', 0)}
    - CTR: {metrics.get('ctr', 0)}%
    - CPC: R$ {metrics.get('cpc', 0)}
    - Impress√µes: {metrics.get('impressions', 0)}
    """

    print("ü§î Consultando Llama 3.3 (Groq)...")
    
    try:
        start_time = time.time()
        chat_completion = groq_client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message},
            ],
            model="llama-3.3-70b-versatile",
            temperature=0.1, 
            response_format={"type": "json_object"}
        )
        end_time = time.time()
        print(f"‚ö° Resposta gerada em {end_time - start_time:.2f}s")

        result_content = chat_completion.choices[0].message.content
        result = json.loads(result_content)
        
        # 4. Salvar Insight no Supabase
        payload = {
            "date": metrics['date'],
            "insight_text": result['insight'],
            "detailed_reason": result.get('detailed_reason', ''),
            "sentiment": result['sentiment'],
            "confidence_score": result['confidence_score']
        }
        
        supabase.table('daily_insights').upsert(payload, on_conflict='date').execute()
        
        print("\n‚úÖ INSIGHT SALVO COM SUCESSO:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"‚ùå Erro na gera√ß√£o/salvamento do insight: {e}")

if __name__ == "__main__":
    generate_insight()